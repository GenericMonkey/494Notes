\documentclass{amsart}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage{bbm}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{xifthen}
\usepackage{cancel}
\usepackage{hyperref}

\setlength{\textwidth}{\paperwidth}
\addtolength{\textwidth}{-2in}
\calclayout

\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\Zn}[1]{\mathbb{Z} / #1 \mathbb{Z}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\dd}[2][ ]{\frac{\partial #1}{\partial #2}} %partial derivative
\newcommand{\dsq}[3][ ]{\frac{\partial^2 #1}             %Second partial
{\ifthenelse { \equal {#2} {#3} }{\partial #2^2}{\partial #2 \partial #3}}}
\newcommand{\defarr}					    %definition iff arrow
{\overset{\textrm{def}}{\Longleftrightarrow}}
\newcommand{\defeq}						    %definition equality sign
{\overset{\textrm{def}}{=}}
\newcommand{\argeq}[1]						%definition equality sign
{\overset{\textrm{#1}}{=}}

\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\orb}{orb}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\stab}{Stab}
\DeclareMathOperator{\sgn}{sign}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\tr}{tr}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem*{unnumlemma}{Lemma}
\newtheorem{fact}[thm]{Fact}
\newtheorem{prop}[thm]{Propostion}
\newtheorem*{claim}{Claim}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
\newtheorem*{ex}{Example}
%==============================================================================
% MATH 494 Collaborative Notes
% This is a collaborative notesheet that consists of notes from each day in Math
% 494, transcribed into Tex format for convenience and security from the
% Notebook Thief. General format:
% Contribute by adding a new section, titled "Month Day, Year"
% This is done in the format \section{Date}
% Tex notes using the numbering system used by Tasho himself. I've set up the
% counters on the theorems, definitions, and "facts" to run in tandem with th
% section that the content is in.
% Make sure to properly wrap all proofs, facts, and definitions using the above
% environments.
% Enjoy!
% Current Collaborators:
% 1. Pranav
% 2.
% 3.
% 4.
%==============================================================================
\begin{document}
\title{Math 494: Honors Algebra II}
\maketitle
\tableofcontents
\section{January 4, 2017} %Pranav
\noindent \textbf{Rings}
\begin{defn} \hspace{0.5cm}
    \begin{enumerate}[a)]
    \item A \textbf{ring} is a tuple $(R, +, \cdot, 0)$ where:
    \begin{itemize}
        \item $R$ is a set
        \item $0 \in R$
        \item $+,\cdot: R \times R \rightarrow R$, $\quad$  $(a,b) \mapsto a + b, a \cdot b$
    \end{itemize}
    subject to:
    \begin{itemize}
        \item $(R, +, 0)$ is an abelian group
        \item $(a \cdot b) \cdot c = a \cdot (b \cdot c)$
        \item $(a + b) \cdot c = a \cdot c + b \cdot c$
        \item $a \cdot (b + c) = a \cdot b + a \cdot c$
    \end{itemize}
    \item A \textbf{ring with unity} is a tuple $(R, +, \cdot, 0, 1)$, where
    $(R,+,\cdot,0)$ is a ring, and $1 \in R$ is subject to $1 \cdot a = a \cdot 1 = a$
    for all $a \in R$.
    \item A ring $(R, +, \cdot, 0)$ is called \textbf{commutative} if $ab = ba$ for all
    $a, b \in R$.
    \item A \textbf{field} is a commutative ring with unity $(R,+,\cdot,0,1)$ such
    that $(R \backslash \{0\}, \cdot, 1)$ is a group.
    \end{enumerate}
\end{defn}
\begin{rmk} \hspace{0.5cm}
    \begin{itemize}
        \item We don't really need to include 0,1 in notation: they are unique
        if they exist
        \item There is a notion of a \textbf{skew field}: ring with unity
        $(R,+,\cdot,0,1)$ such that $(R \backslash \{0\}, \cdot , 1)$ is a group.
        (This drops the commutative condition from the definition of a field).
        \item In French: \textit{corps} is a skew field, and \textit{corps commutatif} is a field.
    \end{itemize}
\end{rmk}
\begin{fact}\label{fact:0prod}
 Let $R$ be a ring. For all $a \in R$, $0 \cdot a = 0$.
\end{fact}
\begin{proof}
    $(0 \cdot a) = (0 + 0) \cdot a = 0 \cdot a + 0 \cdot a \Rightarrow 0 = 0 \cdot a$
\end{proof}
\begin{ex} \hspace{0.5cm}
    \begin{itemize}
        \item $\ZZ$ is a ring, commutative, with unity
        \item $\QQ, \RR, \CC$ are fields
        \item $\HH = \{a + bi + cj + dk \mid a,b,c,d \in \RR \}$ where $i^2 = j^2 = k^2 = ijk = -1$ are
        called the \textbf{Hamiltonian Quaternions} and are a skew-field
        \item $\mathcal{C}_{C}(\RR) = $ functions on $\RR$ with compact
        support \\
        ($\supp(f) = \overline{\{x \in \RR \mid f(x) \neq 0\}}$) is a
        commutative ring without unity
        \item $R = \{\star\}, 0 = 1 = \star$ is the \textbf{zero ring}.
    \end{itemize}
\end{ex}
\begin{fact}
    If $(R,+,\cdot,0,1)$ is a ring with unity and $0 = 1$, then $R$ is the zero ring.
\end{fact}
\begin{proof}
    Take $a \in R$. Then $a = a \cdot 1 = a \cdot 0 = 0$ by Fact \ref{fact:0prod}.
\end{proof}
\noindent \underline{Convention}: Unless otherwise noted, ring will refer to
a commutative ring with 1.
\begin{defn}
    Let $R$ be a ring. Its \textbf{group of units} is
    $$
    R^\times = \{a \in R \mid \exists \, b \in R: ab = 1\}
    $$
\end{defn}
\begin{fact} \hspace{0.5cm}
    \begin{itemize}
        \item For $a \in R^\times$, there is a unique $b \in R$ such that $ab = 1$.
        Write $b = a^{-1}$.
        \item For $a,b \in R^\times$, $a \cdot b \in R^\times$.
    \end{itemize}
\end{fact}
\begin{proof} \hspace{0.5cm}
    \begin{itemize}
        \item Given $b, b^\prime$, we have $b = b \cdot 1 = b(ab^\prime) = (ba)b^\prime = 1 \cdot b^\prime
         = b^\prime$.
         \item $(a \cdot b) \cdot (b^{-1} \cdot a^{-1}) = 1$
    \end{itemize}
\end{proof}
\begin{ex}
    $\RR^\times = \RR \backslash \{0\}$, $\ZZ^\times = \{1, -1\}$
\end{ex}
\begin{defn}
    Let $R, S$ be rings. A \textbf{morphism} $\phi:R \rightarrow S$ is a map of
    sets $\varphi:R \rightarrow S$ satisfying
    \begin{itemize}
        \item $\varphi(a + b) = \varphi(a) + \varphi(b)$
        \item $\varphi(a \cdot b) = \varphi(a) \cdot \varphi(b)$
        \item $\varphi(1) = 1$
    \end{itemize}
\end{defn}
\begin{ex}
    $\varphi:\ZZ \rightarrow \ZZ$ $u \mapsto 0$ is \underline{not} a morphism of
    rings with 1. (it is a morphism of general rings).
\end{ex}
\begin{fact}\label{fact:!morph}
    For any ring $R$ there is a unique morphism $\varphi:\ZZ \rightarrow R$. Given
    $z \in \ZZ$, we write $z_{R}$, or simply $z$ for its image under $\varphi$.
\end{fact}
\begin{ex}
    $5 \in \ZZ$, $5_{\QQ} \in \QQ$ usual number $5$. $5_{\Zn 2} = 1_{\Zn 2}$
\end{ex}
\begin{defn}
    Let $R$ be a ring. A subset $I \subset R$ is called an \textbf{ideal} if
    \begin{itemize}
        \item $I$ is a subgroup of $(R, +, 0)$
        \item $a \cdot f \in I$ for all $a \in R, f \in I$.
    \end{itemize}
\end{defn}
\begin{defn}
    Let $R$ be a ring. A subset $S \subset R$ is called a subring if
    \begin{itemize}
        \item $S$ is a subgroup of $(R, +, 0)$
        \item $a \cdot b \in S$ for all $a, b \in S$.
        \item $1 \in S$.
    \end{itemize}
\end{defn}
\begin{rmk}\hspace{0.5cm}
    \begin{itemize}
        \item The only subset that is both a subring and an ideal is $R$ itself.
        (reason: if $1 \in I$, then $a \cdot 1 \in I$ for all $a \in R$, meaning $I = R$)
        \item $I = \{0\}, I = R$ are always ideals.
        \item In rings without unity, the 2 notions align closer: ideal becomes a special
        case of subring as $1 \in S$ condition is dropped.
    \end{itemize}
\end{rmk}
\begin{ex} \hspace{0.5cm}
    \begin{itemize}
        \item Every subgroup of $(\ZZ, +, 0)$ is an ideal of $\ZZ$.
        \item If $F$ is a field, then $\{0\}, R$ are the only ideals
        \item Let $R = \mathcal{C}_C(\RR), S \in R$ subset.
        $$
        I = \{f \in \mathcal{C}_C(\RR) \mid f \mid_{S} = 0 \}
        $$
        is an ideal
    \end{itemize}
\end{ex}
\begin{defn}
    An ideal $I \in R$ is called \textbf{principal} if $I = \{a \cdot r \mid r \in R\}$
    for some $a \in R$. Then $a$ is called a \textbf{generator}.
\end{defn}
\begin{defn}
    Let $a_1, a_2, \dots a_n \in R$. An \textbf{ideal generated by} $a_1, \dots a_n$ is
    $$
    (a_1, \dots a_n) = \{a_1r_1 + \dots + a_nr_n \mid r_i \in R\}
    $$
\end{defn}
\begin{fact}
    Given ideals $I, J \subset R$ we have
    \begin{itemize}
        \item $I \cap J$ is an ideal
        \item $I + J = \{a + b \mid a \in I, b \in J \}$ is an ideal
        \item $I \cdot J = \left\{\sum\limits_{i = 1}^{n}a_ib_i \mid a_i \in I, b_i \in J \right\}$ is an ideal
    \end{itemize}
\end{fact}
\section{January 6, 2017} %Pranav
\begin{fact}
    Let $\varphi: R \rightarrow S$ be a morphism. Then
    $$
    \ker(\varphi) = \{x \in R \mid \varphi(x) = 0\}
    $$
    is an ideal.
\end{fact}
\begin{proof} (A Pranav Exclusive)
    We first show that the kernel is a subgroup of $(R, +, 0)$. Well, we first show that
    $0 \in \ker(\varphi)$. Well,
    $$
    \varphi(0) = \varphi(0 + 0) = \varphi(0) + \varphi(0)
    $$
    so, we have that $\varphi(0) = 0$ and thus $0 \in \ker(\phi)$.
    Next, we show that inverses are in the kernel as well. \\
    If we have that $\varphi(a) = 0$, then we have
    $$0 = \varphi(0) = \varphi(a + (-a)) = \varphi(a) + \varphi(-a) = \varphi(-a)$$
    Now, we complete this step by proving closure. Assume $a,b \in \ker(\varphi)$. Then,
    $$\phi(a + b) = \phi(a) + \phi(b) = 0 + 0 = 0$$
    Thus, we have that the kernel is a subgroup. Now, we verify the second condition.
    Fix $a \in R$ and $f \in \ker(\varphi)$. We have that
    $$
    \phi(a \cdot f) = \phi(a) \cdot \phi(f) = \phi(a) \cdot 0 = 0
    $$
    Thus, we have that $a \cdot f \in \ker(\varphi)$, meaning that $\ker(\varphi)$
    is an ideal.
\end{proof}
\noindent Question: Is every ideal the kernel of morphism?
\begin{prop}
    Let $R$ be a ring, $I \subset R$ an ideal. Let $R / I$ be the quotient of
    abelian groups and $p: R \rightarrow R / I$ the canonical projection. Then there is a
    unique product map
    $$
    \cdot: R/I \times R/I \rightarrow R/I
    $$
    making $R / I$ into a ring such that $p$ is a morphism.
\end{prop}
\begin{proof}
    For $p$ to be a morphism of rings, we need
    \begin{itemize}
        \item $p(1_R) = 1_{R/I}$
        \item The following diagram to commute
        \[ \begin{tikzcd}[%
        ,every arrow/.append style={maps to}
        ,every label/.append style={font=\normalsize}
        ,row sep=1.5cm
        ,column sep=1.5cm]
        R \times R \arrow{r}{\cdot_R} \arrow[swap]{d}{p \times p} & R \arrow{d}{p} \\%
        R/I \times R/I \arrow{r}{\cdot_{R/I}}& R/I
        \end{tikzcd}
        \]
    \end{itemize}
    Uniqueness of $\cdot_{R/I}$ follows from surjectivity of $p \times p$ (each element
    in $R / I \times R/I$ must go precisely to the result of the composition of $p$ and
    $\cdot_R$) \\
    For existence, define $1_{R/I} = p(1_R)$ and $(a + I) \cdot (b + I) \defeq (a \cdot b) + I$.
    We have to show this is well-defined (i.e it is independent of choice of $a, b$). \\
    Well, choose $a^\prime, b^\prime$ such that $a^\prime  + I = a + I, b^\prime + I = b + I$.
    Thus, $a^\prime = a + i$, $b^\prime = b + j$ for some $i, j \in I$. Then
    $$
    (a^\prime + I)(b^\prime + I) = (a^\prime \cdot b^\prime) + I = ((a + i)\cdot(b + j)) + I =
    (a\cdot b + a \cdot j + b \cdot i + i \cdot j) + I = a\cdot b + I
    $$
    as we note that $a \cdot j, b \cdot i$, and $i \cdot j$ are all in $I$ as $I$
    is an ideal. \\
    We have that all of the ring axioms for $R / I$ are inherited from the ring
    structure on $R$.
\end{proof}
\begin{rmk}
    $\ker(p) = I$
\end{rmk}
\begin{thm}\label{thm:homomorphism} \textbf{(Homomorphism Theorem):}
    Let $\phi: R \rightarrow S$ be a morphism of rings, $I \subset \ker(\varphi)$ be
    an ideal of $R$. There is a unique morphism $\overline{\varphi}: R/I \rightarrow S$
    such that $\overline{\varphi} \circ p = \varphi$ i.e.
    \[
\begin{tikzcd}[,every arrow/.append style={maps to}
,every label/.append style={font=\normalsize},column sep=1.5em]
 & R/I \arrow{dr}{\overline{\varphi}} \\
R \arrow{ur}{p} \arrow{rr}{\varphi} && S
\end{tikzcd}
\]
commutes. Moreover, $\overline{\varphi}$ is injective $\iff$ $\ker(\varphi) = I$
\end{thm}
\begin{proof}
    All statements follow from looking at the abelian group $(R, +, 0)$ and its
    subgroup $I$, except multiplicativity of $\overline{\varphi}$. \\
    (A Pranav Exclusive) Some justification:
    the uniqueness of this morphism follows because the projection map is surjective, meaning that in
    order for the composition to be commutative, we must have that each element in $R / I$ maps exactly
    to where its associated element maps under $\varphi$. Now, the existence. We simply need to check that
    the map $\overline{\varphi}$ that sends $a + I$ to $\varphi(a)$ is well defined and is a morphism. We note that
    the additive morphism properties are inherited from the fact that $\varphi$ is a morphism itself. So, we check
    the well-definedness of $\overline{\varphi}$. Pick 2 representatives of $a + I$, call them $a + I$ and
    $a^\prime + I$. We have that $a^\prime = a + i$ for $i \in I$. Then, we have that
    $$
    \overline{\varphi}(a^\prime + I) = \overline{\varphi}(a + i + I) = \overline{\varphi}(a + I) + \overline{\varphi}(i + I) =
    \overline{\varphi}(a + I) + \overline{\varphi}(I) = \overline{\varphi}(a + I) + 0
    $$
    as we have that $\varphi(i) = 0$ for all $i \in I$ (since $I \subset \ker(\varphi)$). We finally verify the injective
    biconditional. Assume $\overline{\varphi}$ is injective. We already have that $I \subset \ker(\varphi)$.
    Now, since $\overline{\varphi}$ is injective, its kernel is trivial, and is thus the identity of $R / I$, namely $I$ itself.
    For any $g \in \ker(\varphi)$ we note that $g + I$ must belong to the kernel of $\overline{\varphi}$, meaning that
    $g + I = I$ and thus $g \in I$. This gives us double containment and thus equality. \\
    Now, assume that $\ker(\varphi) = I$. We consider $\ker(\overline{\varphi})$. This is exactly the collection
    $\{a + I \mid a \in \ker(\varphi) \}$. Thus, this is $\{a + I \mid a \in I\}$ and thus we have that
    $\ker(\overline{\varphi}) = I$. Since the kernel of $\overline{\varphi}$ is trivial, we have that
    $\overline{\varphi}$ is injective. \\
    Checking Multiplicativity: Let $A,B \in R/I$. Choose $a,b \in R$ such that $p(a) = A, p(b) = B$. Then
    $$
    \overline{\varphi}(A \cdot B) = \overline{\varphi}(p(a)\cdot p(b)) =
    \overline{\varphi}(p(ab)) = \varphi(ab) = \varphi(a)\varphi(b) =
    \overline{\varphi}(p(a))\overline{\varphi}(p(b)) = \overline{\varphi}(A)\overline{\varphi}(B)
    $$
\end{proof}
\begin{defn}
    Let $R$ be a ring.
    \begin{itemize}
        \item Let $a,b \in R$. We say that \textbf{$a$ divides $b$} (denoted $a \mid b$)
        if there is $c \in R$ such that $ac = b$.
        \item We say $0 \neq a \in R$ is a \textbf{zero divisor} if there is
        $0 \neq b \in R$ such that $ab = 0$.
        \item We call $R$ a \textbf{domain} (or \textbf{integral domain}) if it has
        no zero divisors.
    \end{itemize}
\end{defn}
\begin{fact}
    $a \mid b \iff (b) \subset (a) \iff b \in (a)$
\end{fact}
\begin{proof} (A Pranav Exclusive)
    We first show the first forward implication. Assume that $a \mid b$. Then, there is
    $c \in R$ such that $ac = b$. Now, fix $g \in (b)$. It is of the form $br$ for some
    $r \in R$. Thus, we have that $g = (ac)r = a(cr)$. Since $cr \in R$, we have that $g \in (a)$. \\
    Next, we show the second forward implication. Assume that $(b) \subset (a)$. Well,
    $b \in (b) \subset (a)$. \\
    Finally, we show that $b \in (a)$ implies the original condition. Well, if $b \in (a)$, then
    $b = ar$ for $r \in R$. This is exactly what it means for $a \mid b$! Thus, we have
    shown equality of the above statements.
\end{proof}
\begin{fact} (Cancellation Law) If $a \neq 0 \in R$ is not a zero divisor, then
    for $x,y \in R$
    $$
    ax = ay \Rightarrow x = y
    $$
\end{fact}
\begin{proof}
    $ax = ay \iff a(x - y) = 0$. $a \neq 0$ implies that $x - y = 0$ as $a$ is not
    a zero divisor.
\end{proof}
\begin{defn}
    An ideal $I \subsetneq R$ is called
    \begin{itemize}
        \item \textbf{prime} if $a \cdot b \in I$ implies $a \in I$ or $b \in I$ for all $a,b \in R$.
        \item \textbf{maximal} if $I$ and $R$ are the only ideals containing $I$.
    \end{itemize}
\end{defn}
\begin{ex}
    In $R = \ZZ$, the ideals are of the form $n\ZZ$. $n\ZZ$ is prime $\iff$ $n$ is prime or $n = 0$.
\end{ex}
\begin{proof}
    (A Pranav Exlusive). We start with the forward direction. We proceed by contrapositive.
    Assume that $n \neq 0$ and that $n$ is not prime. Then, $n$ is composite (we exclude $n = 1$ as
    we must have a properly contained ideal by definition). Thus, we have that $n = ab$ for some $1 < a,b < n$.
    Note that we have $ab = n \in n\ZZ$, but we have that both $a$ and $b$ are less than $n$, and thus there is no $z \in \ZZ$
    such that $nz = a$ or $nz = b$. This means that $n\ZZ$ is not prime, as we have found $a,b$ such that
    $ab \in n\ZZ$ but neither $a$ nor $b$ are in $n\ZZ$. \\
    Now, the reverse direction. First, we show the condition for $n$ prime. Assume that we have $a,b \in \ZZ$ such that $ab \in n\ZZ$.
    This means that we have $ab = nq$ for some $q \in \ZZ$. In particular, this means that $n$ divides
    the product $ab$. However, we note that as $n$ is prime, we have that $n$ must divide $a$
    or $b$ by Euclid's lemma. Thus, we have that either $a = nr$ or $b = nr$ (or both), which implies
    that $a \in n\ZZ$ or $b \in n\ZZ$. Next, for $n = 0$. Well, if $ab \in 0\ZZ$, then $ab = 0$. This in $\ZZ$ implies
    that either $a$ or $b$  is $0$ and is also in $n\ZZ$. This completes the reverse direction.
\end{proof}
\begin{thm}\label{thm:ideals}
    Let $R$ be a ring.
    \begin{enumerate}[i)]
        \item $R$ is a domain $\iff \{0\}$ is prime.
        \item $R / I$ is a domain $\iff I \subset R$ is a prime ideal.
        \item Let $\varphi: R \rightarrow S$ be a morphism, $S$ a domain. Then
        $\ker(\varphi)$ is prime. The converse is true if $\varphi$ is surjective.
        \item $R$ is a field $\iff \{0\}$ is maximal.
        \item $R / I$ is a field $\iff I \subset R$ is a maximal ideal.
        \item Every field is a domain.
        \item Every maximal ideal is prime.
    \end{enumerate}
\end{thm}
\begin{proof}
    We first claim that iii) implies ii) which in turn implies i). First, for iii) implies
    ii), we note that letting $S$ be $R / I$ (which means $\varphi$ is the projection
    map $p$ (which is definitely surjective)) gives us ii). (We have that $\ker(p) = I$).\\
    ii) implies i) simply by letting $I$ be the zero ideal. \\
    Now, we prove statement iii). \\
    Let $a, b \in R$ such that $a \cdot b \in \ker(\varphi)$. Then $0 = \varphi(a \cdot b) = \varphi(a)\varphi(b)$.
    Since we have that $S$ is a domain, then we have no zero divisors, meaning that either
    $\varphi(a) = 0$ or $\varphi(b) = 0$. This in turn implies that either $a \in \ker(\varphi)$ or $b \in \ker(\varphi)$,
    so we have show that $\ker(\varphi)$ is a prime ideal. Now, the converse assuming surjectivity.
    We want to show that $S$ has no zero divisors. Well, fix $A,B \in S$ such that $A \cdot B = 0$.
    Since $\varphi$ is surjective, we have $a, b \in R$ such that $\varphi(a) = A$ and $\varphi(b) = B$.
    Then, we have $0 = \varphi(a)\varphi(b) = \varphi(ab)$, meaning that $ab$ is in $\ker(\varphi)$.
    Because we assume that $\ker(\varphi)$ is prime, this in turn implies that either
    $a$ or $b$ is in $\ker(\varphi)$ meaning that either $\varphi(a) = 0$ or $\varphi(b) = 0$.
    This means that either $A$ or $B$ is 0, and thus $S$ is a domain, as desired. \\
    Next, note that v) implies iv). This comes from letting $I$ be the zero ideal. \\
    The proof of v) comes from the bijection
    $$
    \{\textrm{ideals in $R$ containing $I$}\} \leftrightarrow \{\textrm{ideals in $R/I$}\}
    $$
    This is a homework problem. \\
    Now, we show vi). Assume that $F$ is a field. Pick $a,b \in F$ such that $a \cdot b = 0$
    with $a \neq 0$. We will show that $b$ must be 0, thereby showing that $F$ is a domain.
    Well, since $a \neq 0$, and $F \backslash \{0\}$ is a group, we have that $a^{-1}$ exists.
    Thus, we have that $ab = 0$ implies that $a^{-1}ab = 0$ and thus $b = 0$, as desired. \\
    vii) follows from the facts vi), v) and ii). We have that
    \begin{center}
        $I$ is a maximal ideal $\overset{\textrm{v}}{\iff}$ $R/I$ is a field $\overset{\textrm{vi}}{\Rightarrow}$ $R / I$ is a domain
        $\overset{\textrm{ii}}{\iff}$ I is prime.
    \end{center}
\end{proof}
\section{January 9, 2017}
\begin{defn}
    Let $R$ b a domain. The canonical morphism $\ZZ \rightarrow R$ of Fact \ref{fact:!morph} has
    a prime ideal as its kernel. By Thm \ref{thm:ideals}, this is of the form
    $p\ZZ$ with $p$ prime of $p = 0$. We call $p$ the \textbf{characteristic} of $R$.
\end{defn}
\begin{ex}
\[
\begin{tabular}{ll}
    char$(\ZZ) = 0$ & char$(\Zn 3) = 3$ \\
    char$(\QQ) = 0$ & char$(\Zn 6)$ doesn't exist! $\Zn 6 $ is not a domain.
\end{tabular}
\]
\end{ex}
\begin{unnumlemma}
\textbf{(Zorn's Lemma)} (from Artin). An \textbf{inductive} (every totally ordered
subset has an upper bound) partially ordered set $S$ has at least one maximal element.
\end{unnumlemma}
\begin{thm}
    Let $R$ be a ring. Every proper ideal is contained in a max ideal.
\end{thm}
\begin{proof}
    Let $I \subset R$ be a proper ideal. Let $\mathcal{M}$ be the set of all proper
    ideals of $R$ that contain $I$, with partial order given by inclusion. \\
    Let $\mathcal{C} \subset \mathcal{M}$ be a totally ordered subset.
    \begin{claim}
        $J_0 = \left(\bigcup\limits_{J \in \mathcal{C}}{J}\right) \in \mathcal{M}$
    \end{claim}
    \begin{proof} (of claim). We want to show that $J_0$ is a proper ideal containing
        $I$. First, we show it is an ideal by showing closure of the subgroup and the
        ideal multiplicative closure. Let $f_1, f_2 \in J_0$ and $a \in R$. Now, this means there
        is $J_1, J_2 \in \mathcal{C}$ such that $f_1 \in J_1$ and $f_2 \in J_2$. However,
        since $\mathcal{C}$ is totally ordered, we have that the larger of $J_1$ and $J_2$
        contains both $f_1$ and $f_2$, meaning that we have the existence of $J \in \mathcal{C}$
        such that $f_1,f_2 \in J$. Since $J$ is an ideal, we have that $f_1 + f_2 \in J$ and that
        $a \cdot f_1 \in J$. This thus implies that since $J \in \mathcal{C}$, we have that
        $a \cdot f_1$ and $f_1 + f_2$ are both in $J_0$. Thus $J_0$ is an ideal. Since $I \in \mathcal{C}$,
        we also have that $I \subset J_0$. Finally, $J_0$ is not $R$, because otherwise $1 \in J_0$,
        which would mean that $1 \in J$ for some $J \in \mathcal{C}$. This would then imply that
        that $J = R$, which is not possible as $J$ itself is a proper ideal. Thus, we have that $J_0 \in \mathcal{M}$.
    \end{proof}
    Thus, for every totally ordered subset of $\mathcal{M}$, we have the existence of an
    upper bound (namely $J_0$). This gives us, by Zorn's Lemma, that $\mathcal{M}$ has
    a maximal element. This maximal element is exactly what we wished to show existed.
\end{proof}
\begin{defn}
Let $R,S$ be rings. Their product is the set $R \times S$ with component-wise
operations
\begin{itemize}
    \item $(r,s) + (r^\prime, s^\prime) = (r + r^\prime, s + s^\prime)$
    \item $(r,s) \cdot  (r^\prime, s^\prime) = (r \cdot r^\prime, s \cdot s^\prime)$
    \item $1_{R \times S} = (1_R, 1_S), 0_{R \times S} = (0_R, 0_S)$
\end{itemize}
\end{defn}
\begin{rmk}
    Given morphisms $\varphi_1:R \rightarrow S_1, \varphi_2:R \rightarrow S_2$, we
    get a unique morphism $\varphi_{1} \times \varphi_2: R \rightarrow S_1 \times S_2$.
\end{rmk}
\begin{rmk}
    Given $I,J \subset R$ ideals we have
    $$
    I \cdot J \subset I \cap J \subset I, J \subset I + J
    $$
\end{rmk}
\begin{defn}
    Two ideals $I,J \subset R$ are \textbf{coprime} if $I + J = R$.
\end{defn}
\begin{thm}
    \textbf{(Chinese Remainder Theorem)} Let $R$ be a ring, $I_1, \dots I_n \subset R$
    be pairwise coprime ideals. Then the natural morphism
    $$
    p: R \rightarrow R / I_1 \times R / I_2 \times \dots \times R / I_n
    $$
    factors through the quotient $R / (I_1 \cap I_2 \cap \dots \cap I_n)$ and induces
    an isomorphism of rings
    $$
    \overline{p}: R / (I_1 \cap I_2 \cap \dots \cap I_n) \rightarrow R / I_1 \times R / I_2 \times \dots \times R / I_n
    $$
    Moreover, $I_1 \cdot I_2 \cdots I_n = I_1 \cap I_2 \cap \dots I_n$
\end{thm}
\begin{proof}
    As $p$ is the natural morphism to a product of rings, we let $p = p_1 \times p_2 \dots \times p_n$,
    where each $p_i$ is the projection morphism from $R$ to $R / I_i$. Now, we can say that
    $\ker(p) = \{r \in R \mid 0 = p_1(r), 0 = p_2(r), \dots 0 = p_n(r) \}$. Well, since each $p_i$ by definition has
    kernel exactly $I_i$, this is the same as saying that
    $\ker(p) = \{r \in R \mid r \in I_1 \cap I_2 \cap \dots \cap I_n \}$. \\
    By the homomorphism theorem (\ref{thm:homomorphism}), we have that $p$ factors through
    $R / I_1 \cap I_2 \cap \dots I_n$ and also induces an injective ring morphism
    $\overline{p}: R/ I_1 \cap \dots \cap I_n \rightarrow R/I_1 \times \dots R/I_n$.
    \begin{claim}
        $\overline{p}$ is also surjective, and hence a isomorphism.
    \end{claim}
    \begin{proof} (of claim)
        We note that since each of the ideals are coprime, we have that $I_1 + I_k = R$.
        Now, we also note that $R \cdot R = R$. Thus, we can express
        $$
        R = (I_1  + I_2) \cdot (I_1 + I_3) \cdots (I_1 + I_n)
        $$
        expanding the product, we note that by the earlier remark that any term
        containing an $I_1$ (which is almost all of them) will be contained in
        $I_1$. The only term that is outside arises from selecting the second term
        in every single term of the product, so we can write that the above expression
        is
        $$
        \subset I_1 + (I_2 \cdot I_3 \cdots I_n)
        $$
        Now, since $R \subset I_1 + (I_2 \cdot I_3 \cdots I_n)$, we can take
        $v_1 \in I_1$ and $u_1 \in I_2 \cdots I_n$ such that $u_1 + v_1 = 1$.
        Now, since $u_1 \in I_2 \cdots I_n$, $u_1 \in I_j$ for $j \neq 1$. Thus,
        we can say that $u_1$ maps to $0_{R/I_j}$ under the projection map, as it is
        in the kernel. \\
        Similarly, since $u_1 = 1 - v_1$, with $v_1 \in I_1$, we have that $u_1 \in 1 + I$,
        meaning that $u_1$ maps to $1_{R/I_1}$ under the projection map. \\
        So, we have (abusing notation) that $u_1 = 1$ in $R/I_1$ and $u_1 = 0$ in $R/I_j$ for $j \neq 1$
        (really, as we showed above, it belongs to the associated cosets). \\
        Now, we can repeat this construction with any $I_i$ instead of $I_1$.
        Thus, we get for each such construction a $v_i \in I_i$ and $u_i \in I_1 \cdot I_2 \cdots \widehat{I_i} \cdots I_n$
        With this construction, we now have the existence of the $u_i$ that belong
        to the $1$ coset in exactly $R/I_i$ and the $0$ coset in all remaining $R/I_j$.
        With this, we can prove surjectivity.
        Fix any $(x_1, \dots x_n) \in R/I_1 \times \dots R/I_n$. We have that there exists
        an associated $r_1, \dots r_n \in R$ such that $p_1(r_1) = x_1, \dots p_n(r_n) = x_n$.
        Now, if we consider the element $r \in R$ that equals $u_1r_1 + u_2r_2 \dots u_nr_n$,
        note that $p(r) = (p_1(r), p_2(r) \dots p_n(r))$. However, since the $u_i$ map to $1$ under
        $p_i$ and to $0$ otherwise, this maps precisely to $(x_1, \dots x_n)$. Thus, we have
        that $p(r)$ maps to the desired element in the product, meaning that the
        associated coset will map to the desired element under $\overline{p}$. This proves
        surjectivity.
    \end{proof}
    Thus, we have that $\overline{p}$ is an isomorphism. Now, we show the second part of
    part of the statement. \\
    Well, we know by definition that $I_1 \cdot I_2 \cdots I_n \subset I_1 \cap \dots \cap I_n$. So,
    we simply need to show the other containment, which we do by induction on $n$. \\
    $n = 1$: $I_1 \subset I_1$. \\
    $n = 2$: Take $u_1 \in I_1$ and $u_2 \in I_2$ such that $1 = u_1 + u_2$ (this exists as $I_1 + I_2 = R$.)
    Now, for any $u \in I_1 \cap I_2$, we have
    $$
    u = u \cdot 1 = u \cdot (u_1 + u_2) = u \cdot u_1 + u \cdot u_2
    $$
    Since $u \in I_1$ and $u \in I_2$, we have $u \cdot u_1 \in I_2 \cdot I_1$ and
    $u \cdot u_2 \in I_1 \cdot I_2$. Thus, we have the sum in $I_1 \cdot I_2$. This gives us
    $I_1 \cap I_2 \in I_1 \cdot I_2$. \\
    Now, for general $n$. By the inductive hypothesis, we have that
    $I_1 \cap I_2 \dots I_n \subset (I_1 \cdots I_{n-1}) \cap I_n$. From the claim above,
    we know that $R = (I_1 \cdot I_{n-1}) + I_n$. This implies thus that the ideals
    $(I_1 \cdots I_{n-1})$ and $I_n$ are coprime. Thus, applying the $n = 2$ case on these
    2 ideals, we have that $(I_1 \cdots I_{n-1}) \cap I_n \subset (I_1 \cdots I_{n-1}) \cdot I_n$,
    thereby proving the desired result. 
\end{proof}
\end{document}
